{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset: Fake News | Kaggle : https://www.kaggle.com/c/fake-news/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = 'train_refatorado.csv'\n",
    "path_test = 'test.csv'\n",
    "\n",
    "train_data = pd.read_csv(path_train, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Classification of variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>Qualitative Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>title</td>\n",
       "      <td>Qualitative Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>author</td>\n",
       "      <td>Qualitative Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text</td>\n",
       "      <td>Qualitative Nominal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>label</td>\n",
       "      <td>Discrete Quantitative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variable         Classification\n",
       "0       id    Qualitative Nominal\n",
       "1    title    Qualitative Nominal\n",
       "2   author    Qualitative Nominal\n",
       "3     text    Qualitative Nominal\n",
       "4    label  Discrete Quantitative"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = [[\"id\",\"Qualitative Nominal\"],[\"title\",\"Qualitative Nominal\"],\n",
    "         [\"author\",\"Qualitative Nominal\"],[\"text\",\"Qualitative Nominal\"],\n",
    "         [\"label\",\"Discrete Quantitative\"]]\n",
    "\n",
    "filing = pd.DataFrame(table, columns=[\"Variable\", \"Classification\"])\n",
    "filing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* id: unique id for a news article\n",
    "* title: the title of a news article\n",
    "* author: author of the news article\n",
    "* text: the text of the article; could be incomplete\n",
    "* label: a label that marks the article as potentially unreliable\n",
    "* 1: unreliable\n",
    "* 0: reliable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Profiting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the first ten records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title_author_text</th>\n",
       "      <th>token_title</th>\n",
       "      <th>token_author</th>\n",
       "      <th>token_text</th>\n",
       "      <th>token_title_author_text</th>\n",
       "      <th>...</th>\n",
       "      <th>verbos</th>\n",
       "      <th>substantivos_vs_comprimento</th>\n",
       "      <th>adjetivos_vs_comprimento</th>\n",
       "      <th>verbos_vs_comprimento</th>\n",
       "      <th>substantivos_vs_palavras</th>\n",
       "      <th>adjetivos_vs_palavras</th>\n",
       "      <th>verbos_vs_palavras</th>\n",
       "      <th>countagem_palavras_title</th>\n",
       "      <th>media_palavras_len</th>\n",
       "      <th>por_cento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276</td>\n",
       "      <td>4 Secrets About True Leaders</td>\n",
       "      <td>WakingTimes</td>\n",
       "      <td>Waking Times \\nYou can only get so far with or...</td>\n",
       "      <td>1</td>\n",
       "      <td>4 Secrets About True Leaders WakingTimes Wakin...</td>\n",
       "      <td>['4', 'secrets', 'about', 'true', 'leaders']</td>\n",
       "      <td>['wakingtimes']</td>\n",
       "      <td>['waking', 'times', 'you', 'can', 'only', 'get...</td>\n",
       "      <td>['4', 'secrets', 'about', 'true', 'leaders', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5092</td>\n",
       "      <td>Re: 55 Reasons Why California Is The Worst Sta...</td>\n",
       "      <td>ken williams</td>\n",
       "      <td>55 Reasons Why California Is The Worst State I...</td>\n",
       "      <td>1</td>\n",
       "      <td>Re: 55 Reasons Why California Is The Worst Sta...</td>\n",
       "      <td>['re', '55', 'reasons', 'why', 'california', '...</td>\n",
       "      <td>['ken', 'williams']</td>\n",
       "      <td>['55', 'reasons', 'why', 'california', 'is', '...</td>\n",
       "      <td>['re', '55', 'reasons', 'why', 'california', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>9.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>713</td>\n",
       "      <td>Teenage Boy KNOCKS OUT His Classmate For Assau...</td>\n",
       "      <td>shelby andrews</td>\n",
       "      <td>0 comments \\nNot a lot of teenage boys would g...</td>\n",
       "      <td>1</td>\n",
       "      <td>Teenage Boy KNOCKS OUT His Classmate For Assau...</td>\n",
       "      <td>['teenage', 'boy', 'knocks', 'out', 'his', 'cl...</td>\n",
       "      <td>['shelby', 'andrews']</td>\n",
       "      <td>['0', 'comments', 'not', 'a', 'lot', 'of', 'te...</td>\n",
       "      <td>['teenage', 'boy', 'knocks', 'out', 'his', 'cl...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8239</td>\n",
       "      <td>BAHAHA! Wanna bet Hillary made THIS face when ...</td>\n",
       "      <td>Sam J.</td>\n",
       "      <td>â€” Adam Baldwin (@AdamBaldwin) October 28, 2016...</td>\n",
       "      <td>1</td>\n",
       "      <td>BAHAHA! Wanna bet Hillary made THIS face when ...</td>\n",
       "      <td>['bahaha', 'wanna', 'bet', 'hillary', 'made', ...</td>\n",
       "      <td>['sam', 'j']</td>\n",
       "      <td>['adam', 'baldwin', 'adambaldwin', 'october', ...</td>\n",
       "      <td>['bahaha', 'wanna', 'bet', 'hillary', 'made', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.085366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036585</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5302</td>\n",
       "      <td>CNN Talker Famous for Saying 'Pu***' on Air La...</td>\n",
       "      <td>Mike Miller</td>\n",
       "      <td>Share on Twitter The Wildfire is an opinion pl...</td>\n",
       "      <td>1</td>\n",
       "      <td>CNN Talker Famous for Saying 'Pu***' on Air La...</td>\n",
       "      <td>['cnn', 'talker', 'famous', 'for', 'saying', '...</td>\n",
       "      <td>['mike', 'miller']</td>\n",
       "      <td>['share', 'on', 'twitter', 'the', 'wildfire', ...</td>\n",
       "      <td>['cnn', 'talker', 'famous', 'for', 'saying', '...</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.099010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.029703</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              title          author  \\\n",
       "0   276                       4 Secrets About True Leaders     WakingTimes   \n",
       "1  5092  Re: 55 Reasons Why California Is The Worst Sta...    ken williams   \n",
       "2   713  Teenage Boy KNOCKS OUT His Classmate For Assau...  shelby andrews   \n",
       "3  8239  BAHAHA! Wanna bet Hillary made THIS face when ...          Sam J.   \n",
       "4  5302  CNN Talker Famous for Saying 'Pu***' on Air La...     Mike Miller   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  Waking Times \\nYou can only get so far with or...      1   \n",
       "1  55 Reasons Why California Is The Worst State I...      1   \n",
       "2  0 comments \\nNot a lot of teenage boys would g...      1   \n",
       "3  â€” Adam Baldwin (@AdamBaldwin) October 28, 2016...      1   \n",
       "4  Share on Twitter The Wildfire is an opinion pl...      1   \n",
       "\n",
       "                                   title_author_text  \\\n",
       "0  4 Secrets About True Leaders WakingTimes Wakin...   \n",
       "1  Re: 55 Reasons Why California Is The Worst Sta...   \n",
       "2  Teenage Boy KNOCKS OUT His Classmate For Assau...   \n",
       "3  BAHAHA! Wanna bet Hillary made THIS face when ...   \n",
       "4  CNN Talker Famous for Saying 'Pu***' on Air La...   \n",
       "\n",
       "                                         token_title           token_author  \\\n",
       "0       ['4', 'secrets', 'about', 'true', 'leaders']        ['wakingtimes']   \n",
       "1  ['re', '55', 'reasons', 'why', 'california', '...    ['ken', 'williams']   \n",
       "2  ['teenage', 'boy', 'knocks', 'out', 'his', 'cl...  ['shelby', 'andrews']   \n",
       "3  ['bahaha', 'wanna', 'bet', 'hillary', 'made', ...           ['sam', 'j']   \n",
       "4  ['cnn', 'talker', 'famous', 'for', 'saying', '...     ['mike', 'miller']   \n",
       "\n",
       "                                          token_text  \\\n",
       "0  ['waking', 'times', 'you', 'can', 'only', 'get...   \n",
       "1  ['55', 'reasons', 'why', 'california', 'is', '...   \n",
       "2  ['0', 'comments', 'not', 'a', 'lot', 'of', 'te...   \n",
       "3  ['adam', 'baldwin', 'adambaldwin', 'october', ...   \n",
       "4  ['share', 'on', 'twitter', 'the', 'wildfire', ...   \n",
       "\n",
       "                             token_title_author_text  ...  verbos  \\\n",
       "0  ['4', 'secrets', 'about', 'true', 'leaders', '...  ...       0   \n",
       "1  ['re', '55', 'reasons', 'why', 'california', '...  ...       1   \n",
       "2  ['teenage', 'boy', 'knocks', 'out', 'his', 'cl...  ...       1   \n",
       "3  ['bahaha', 'wanna', 'bet', 'hillary', 'made', ...  ...       3   \n",
       "4  ['cnn', 'talker', 'famous', 'for', 'saying', '...  ...       3   \n",
       "\n",
       "   substantivos_vs_comprimento  adjetivos_vs_comprimento  \\\n",
       "0                     0.107143                       0.0   \n",
       "1                     0.084746                       0.0   \n",
       "2                     0.110000                       0.0   \n",
       "3                     0.085366                       0.0   \n",
       "4                     0.099010                       0.0   \n",
       "\n",
       "   verbos_vs_comprimento  substantivos_vs_palavras  adjetivos_vs_palavras  \\\n",
       "0               0.000000                  0.600000                    0.0   \n",
       "1               0.016949                  0.454545                    0.0   \n",
       "2               0.010000                  0.647059                    0.0   \n",
       "3               0.036585                  0.466667                    0.0   \n",
       "4               0.029703                  0.555556                    0.0   \n",
       "\n",
       "   verbos_vs_palavras  countagem_palavras_title  media_palavras_len  por_cento  \n",
       "0            0.000000                         0                11.0   0.000000  \n",
       "1            0.090909                         0                 5.5   9.090909  \n",
       "2            0.058824                         0                 6.5   0.000000  \n",
       "3            0.200000                         2                 2.5   0.000000  \n",
       "4            0.166667                         2                 5.0   0.000000  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create two new columns, called title_author_text and len_title_author_text, to store the concatenation of the title, author, text and the size of this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['title_author_text'] = train_data['title'] + ' ' + train_data['author'] + ' ' + train_data['text']\n",
    "train_data['len_title_author_text'] = [len(x) for x in train_data['title_author_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     15848.000000\n",
      "mean       4812.488579\n",
      "std        5323.513156\n",
      "min          23.000000\n",
      "25%        1826.000000\n",
      "50%        3631.000000\n",
      "75%        6539.250000\n",
      "max      143053.000000\n",
      "Name: len_title_author_text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "detail = train_data['len_title_author_text'].describe()\n",
    "print(detail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate the data set in 80% training and 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Feature: 12678\n",
      "Train Data Label: 12678\n",
      "Test Data Feature: 3170\n",
      "Test Data Label: 3170\n"
     ]
    }
   ],
   "source": [
    "#train_features = train_data.drop(['id', 'label'], axis=1)\n",
    "train_features = train_data['title_author_text']\n",
    "train_targets = train_data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, train_targets, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Train Data Feature: {}'.format(len(X_train)))\n",
    "print('Train Data Label: {}'.format(len(y_train)))\n",
    "\n",
    "print('Test Data Feature: {}'.format(len(X_test)))\n",
    "print('Test Data Label: {}'.format(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "# This method is called when RandomState is initialized.\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a token dictionary with max 5000 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_token = 5000\n",
    "token = Tokenizer(num_words = num_token, filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "token.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to truncate and fill in the input sequences so they have the same length for modeling. Vectors of the same length are required to perform the calculation in Keras.\n",
    "We use as maximum sequence size the average of the feature 'len_title_author_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = int(detail['mean'])\n",
    "\n",
    "x_train_token = token.texts_to_sequences(X_train)\n",
    "x_test_token = token.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_seq = sequence.pad_sequences(x_train_token, maxlen=max_review_length)\n",
    "X_test_seq = sequence.pad_sequences(x_test_token, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model:\n",
    "The first layer is the Embedded Layer that uses 32 length vectors to represent each word. The next layer is the LSTM layer with 100 units of memory. As this is a classification problem, we use a Densa output layer with a single neuron and a sigmoid activation function to make the predictions 0 or 1 for the two classes (Unreliable and Reliable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cliente\\Anaconda3\\envs\\University\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_token, output_dim=embedding_vector_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "#model.add(Dense(units = 256, activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent neural networks such as LSTM usually have the problem of overfitting, so let's use the layers of elimation with Dropout Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cliente\\Anaconda3\\envs\\University\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4812, 32)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.2\n",
    "\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the function logloss (binary_crossentropy) and the ADAM optimization algorithm. The model is fit for only two epochs with a batch of 64 ratings to space the weight updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cliente\\Anaconda3\\envs\\University\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "12678/12678 [==============================] - 1373s 108ms/step - loss: 1.8584 - acc: 0.7537\n",
      "Epoch 2/3\n",
      "12678/12678 [==============================] - 1370s 108ms/step - loss: 1.7590 - acc: 0.8433\n",
      "Epoch 3/3\n",
      "12678/12678 [==============================] - 1326s 105ms/step - loss: 1.7719 - acc: 0.8504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x295b6378860>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_seq, y_train, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.25%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_seq, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
