{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkEHVK1IN-Pb"
   },
   "source": [
    "<h2 style=\"text-align: center;\">An&aacute;lise Dataset Twitter</h2>\n",
    "<h2 style=\"text-align: center;\">Detec&ccedil;&atilde;o automatizada de Fake News e o problema da linguagem ofensiva e &oacute;dio</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\"><span style=\"color: #ff0000;\"><strong>AVISO: Os dados utilizados, l&eacute;xicos e cadernos cont&ecirc;m conte&uacute;do racista, sexista, homof&oacute;bico e ofensivo de muitas outras maneiras.</strong></span></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ```\n",
    "@inproceedings{hateoffensive, \n",
    "  title={Automated Hate Speech Detection and the Problem of Offensive Language}, \n",
    "  author={Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar}, \n",
    "  booktitle={Proceedings of the 11th International AAAI Conference on Weblogs and Social Media}, \n",
    "  series={ICWSM '17}, \n",
    "  year={2017}, \n",
    "  location = {Montreal, Canada} \n",
    "  }\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repositório para Thomas Davidson, Dana Warmsley, Michael Macy e Ingmar Weber. 2017. \"Detecção automática de fala de ódio e o problema da linguagem ofensiva\". ICWSM. Você leu o artigo [aqui](https://aaai.org/ocs/index.php/ICWSM/ICWSM17/paper/view/15665) ou a nossa pré-impressão no [Arxiv](https://arxiv.org/abs/1703.04009) . Você pode encontrar mais informações na nossa [página do Github](https://github.com/t-davidson/hate-speech-and-offensive-language) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guia de dados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados são armazenados como um CSV,contendo 5 colunas:\n",
    "\n",
    "`count` = número de usuários do CrowdFlower que codificaram cada tweet (min é 3, algumas vezes mais usuários codificam um tweet quando os julgamentos não são confiáveis por CF).\n",
    "\n",
    "`hate_speech` = número de usuários de CF que julgaram o tweet como discurso de ódio.\n",
    "\n",
    "`offensive_language` = número de usuários de CF que julgaram o tweet ofensivo.\n",
    "\n",
    "`neither` = número de utilizadores de CF que consideraram o tweet não ofensivo nem ofensivo.\n",
    "\n",
    "`class`= rótulo de classe para a maioria dos usuários de CF. 0 - discurso de ódio, 1 - linguagem ofensiva, 2 - neutros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise de Sentimentos usando Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxOmgb7BN-Pc"
   },
   "source": [
    "* Criando modelos para análise de sentimentos de tweets\n",
    "* Teste com Modelo usando tag de negações\n",
    "* Teste com Modelo usando Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9e_mycZN-Pd"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2qP6WFxN-Pg"
   },
   "source": [
    "**Ler arquivo de dados e conta a quantidade de linhas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 911,
     "status": "error",
     "timestamp": 1541680897006,
     "user": {
      "displayName": "Rodrigo Santana Ferreira",
      "photoUrl": "https://lh5.googleusercontent.com/-w5AmPcUma78/AAAAAAAAAAI/AAAAAAAAAPw/2VfgXe2k7sI/s64/photo.jpg",
      "userId": "14710330936720624047"
     },
     "user_tz": 120
    },
    "id": "4slTJKvhN-Pg",
    "outputId": "5a0fbf25-492c-4c06-fdec-30fb0984bf3c"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('labeled_data.csv', encoding='utf-8', sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J8_5WdPjN-Pj"
   },
   "source": [
    "**Exibe as 10 primeiras lihas de tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QI0jMKeN-Pk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1    !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
       "2    !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
       "3    !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
       "4    !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
       "5    !!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just...\n",
       "6    !!!!!!\"@__BrighterDays: I can not just sit up ...\n",
       "7    !!!!&#8220;@selfiequeenbri: cause I'm tired of...\n",
       "8    \" &amp; you might not get ya bitch back &amp; ...\n",
       "9    \" @rhythmixx_ :hobbies include: fighting Maria...\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tweet.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1ciRVrDN-Pl"
   },
   "source": [
    "**Conta a quantidade de linhas de tweets neutros, positivos e negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py:3666: UserWarning: The `factorplot` function has been renamed to `catplot`. The original name will be removed in a future release. Please update your code. Note that the default `kind` in `factorplot` (`'point'`) has changed `'strip'` in `catplot`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py:3666: UserWarning: The `factorplot` function has been renamed to `catplot`. The original name will be removed in a future release. Please update your code. Note that the default `kind` in `factorplot` (`'point'`) has changed `'strip'` in `catplot`.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\seaborn\\categorical.py:3666: UserWarning: The `factorplot` function has been renamed to `catplot`. The original name will be removed in a future release. Please update your code. Note that the default `kind` in `factorplot` (`'point'`) has changed `'strip'` in `catplot`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x248a14fdda0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.factorplot('hate_speech',data=dataset, kind='count', aspect=2)\n",
    "sns.factorplot('offensive_language',data=dataset, kind='count', aspect=2)\n",
    "sns.factorplot('neither',data=dataset, kind='count', aspect=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCDmdHipN-Pv"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            24783\n",
       "count                 24783\n",
       "hate_speech           24783\n",
       "offensive_language    24783\n",
       "neither               24783\n",
       "class                 24783\n",
       "tweet                 24783\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJFE0rWAN-Py"
   },
   "source": [
    "## Pre-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvrKfzJQN-Pz"
   },
   "source": [
    "* Remove linhas duplicadas na base de dados\n",
    "    - Problema na coleta dos dados.\n",
    "* Remove Stopwords\n",
    "* Faz Stemming nos dados\n",
    "* Remove caracteres indesejados como links, pontuação etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iiIbvZbwN-P0"
   },
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(['tweet'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AJh2pkEN-P1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24783"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.tweet.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Coh0XgGqN-P4"
   },
   "source": [
    "## ** Separando tweets e suas Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMwzYhDFN-P4"
   },
   "outputs": [],
   "source": [
    "tweets = dataset['tweet']\n",
    "classes = dataset['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y51tqO69N-P6"
   },
   "source": [
    "** Instala bibliotecas e baixa a base de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mB2zdiTZN-P6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\bruno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bAQswo_N-P8"
   },
   "source": [
    "**Funções de Pre-processamento de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VISYmqMN-P9"
   },
   "outputs": [],
   "source": [
    "def RemoveStopWords(instancia):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1R52LDb2N-QB"
   },
   "outputs": [],
   "source": [
    "def Stemming(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    palavras = []\n",
    "    for w in instancia.split():\n",
    "        palavras.append(stemmer.stem(w))\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1L3Kfr-N-QE"
   },
   "outputs": [],
   "source": [
    "def Limpeza_dados(instancia):\n",
    "    # remove links, pontos, virgulas,ponto e virgulas dos tweets\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    return (instancia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lusLFKwZN-QI"
   },
   "source": [
    "** Entenda como funciona cada função**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDtlMpUmN-QI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fuck bitch dont even suck dick &#128514'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RemoveStopWords('fuck no that bitch dont even suck dick &#128514')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnrJKtZFN-QK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@metroadlib: colored contact in your eyes?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stemming('@metroadlib: colored contacts in your eyes?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFrAgPI9N-QL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@oldpicsarchive hgwells and charlie chaplin  #history #photography'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Limpeza_dados('@oldpicsarchive: H.G.Wells and Charlie Chaplin http://t.co/sTiDDHK3WT\" #History #Photography')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFRbKWfFN-QO"
   },
   "source": [
    "** Aplica as 3 funções de Pre-processamento nos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BAlu-RtDN-QP"
   },
   "outputs": [],
   "source": [
    "def Preprocessing(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "    palavras = [stemmer.stem(i) for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))\n",
    "\n",
    "# Aplica a função em todos os dados:\n",
    "tweets = [Preprocessing(i) for i in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpbDgdfEN-QR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@oldpicsarchiv hgwell charli chaplin #history #photography'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Preprocessing('@oldpicsarchive: H.G.Wells and Charlie Chaplin http://t.co/sTiDDHK3WT\" #History #Photography')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Nr2nQYXN-QS"
   },
   "source": [
    "**Visualize os dados e veja como ficou após o pré-processamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c04o1V3xN-QT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!!! rt @mayasolovely woman complain cleaning hous &amp man alway tak trash',\n",
       " '!!!!! rt @mleew17 boy dat coldtyg dwn bad cuffin dat hoe 1st place!!',\n",
       " '!!!!!!! rt @urkindofbrand dawg!!!! rt @80sbaby4lif ev fuck bitch start cry? confused shit',\n",
       " '!!!!!!!!! rt @c_g_anderson @viva_based look lik tranny',\n",
       " '!!!!!!!!!!!!! rt @shenikarobert shit he might tru might fak bitch told ya &#57361',\n",
       " '!!!!!!!!!!!!!!!!!!\"@t_madison_x shit blow meclaim faithful somebody still fucking hoes! &#128514&#128514&#128514\"',\n",
       " '!!!!!!\"@__brighterday sit hat anoth bitch got much shit going on!\"',\n",
       " \"!!!!&#8220@selfiequeenbr caus i'm tired big bitch coming us skinny girls!!&#8221\",\n",
       " '\" &amp might get ya bitch back &amp that \"',\n",
       " '\" @rhythmixx_ hobbi includ fighting mariam\" bitch',\n",
       " '\" keek bitch curv everyon \" lol walked conversation lik smh',\n",
       " '\" murd gang bitch gang land \"',\n",
       " '\" hoe smok los ? \" yea go ig',\n",
       " '\" bad bitch thing lik \"',\n",
       " '\" bitch get \"',\n",
       " '\" bitch nigg mis \"',\n",
       " '\" bitch plz whatev \"',\n",
       " '\" bitch lov \"',\n",
       " '\" bitch get cut everyday b \"',\n",
       " '\" black bottl &amp bad bitch \"',\n",
       " '\" brok bitch cant tell nothing \"',\n",
       " '\" cancel bitch lik nin \"',\n",
       " '\" cant see hoe wont chang \"',\n",
       " '\" fuck bitch dont even suck dick \" &#128514&#128514&#128514 kermit vide bout fuck ig',\n",
       " '\" got ya bitch tip toeing hardwood flo \" &#128514',\n",
       " '\" pussy lip lik heaven do \" &#128524',\n",
       " '\" hoe hitting \"',\n",
       " '\" met pussy ocean dr gav pussy pill \" &#128524',\n",
       " '\" need trippy bitch fuck hennessy \"',\n",
       " '\" spend money want bitch busines \"',\n",
       " '\" txt old bitch new bitch pussy wett \"',\n",
       " '\" i\\'d say im back old old bitch would get excited \" &#128524',\n",
       " '\" aint bout murd gam pussy nigg shut \"',\n",
       " '\" toe ain\\'t don pussy stink \"',\n",
       " '\" im don bitt bitch wrap angry bird th app \"',\n",
       " '\" ya bitch \"',\n",
       " '\" aint nothing cut bitch \"',\n",
       " '\" ju meet son ya man as bitch \" #shot',\n",
       " '\" lam crying hoe that te clown \"',\n",
       " '\" lik snoop said 94 dont lov hoe \"',\n",
       " '\" momm said pussy cat insid doghous \"',\n",
       " '\" hated hoe favorit \" #2mw #sevenon #',\n",
       " '\" nic girl bad, mak get naughty bad yell hoe, real nic body south chick, lik em real thick\"',\n",
       " '\" pimp pimp hoe \" futur voic',\n",
       " '\" post pictur pussy get 200 lik \"',\n",
       " '\" pussy powerful drug \" &#128517 #happyhumpday',\n",
       " '\" quick piec pussy call driv \"',\n",
       " '\" running round lik brand new pussy that bout get fucked \"',\n",
       " '\" bitch even worst they\\'ll send guy \"',\n",
       " '\" hoe lik nigg spend money talk bout \"']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "0kqSnklmN-QV"
   },
   "source": [
    "## Criando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OuEc376oN-QV"
   },
   "source": [
    "**Instancia o objeto que faz a vetorização dos dados de texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kPGn3G6N-QW"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL168-e0N-QY"
   },
   "source": [
    "**Aplica o vetorizador nos dados de texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_OufE_5N-QY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "type(freq_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzHXr2TNN-Qa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-vF1aDAN-Qd"
   },
   "source": [
    "**Formato (Linhas, Colunas) da matriz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNuDjTH6N-Qe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24783, 32699)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1ANkhjhN-Qg"
   },
   "source": [
    "**Matriz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g05OeGVCN-Qg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tweets.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MsWdPRkaN-Qj"
   },
   "source": [
    "** Testando o modelo com algumas instâncias simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oKswXL8TN-Qj"
   },
   "outputs": [],
   "source": [
    "# defina instâncias de teste dentro de uma lista\n",
    "testes = ['Im elated i passed on my creative gene to my daughter but she also got the retarded gene too.',\n",
    "          'Love having subs cause when my',\n",
    "          'Steve McNair got murdered by his side bitch man life is crazy',\n",
    "          'Unintended consequences of the current fed regulations.',\n",
    "          'Lakers are a purple and yellow garbage can']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5qgbrDPN-Qm"
   },
   "source": [
    "**Aplica a função de Pré-processamento nos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rbcyd6wN-Qm"
   },
   "outputs": [],
   "source": [
    "testes = [Preprocessing(i) for i in testes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vh-MK_RBN-Qo"
   },
   "outputs": [],
   "source": [
    "# Transforma os dados de teste em vetores de palavras.\n",
    "freq_testes = vectorizer.transform(testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rWwXiAsLN-Qp"
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not numpy.int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-55eff26de4bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fazendo a classificação com o modelo treinado.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtestes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodelo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq_testes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;34m\", \"\u001b[0m\u001b[1;33m+\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not numpy.int64"
     ]
    }
   ],
   "source": [
    "# Fazendo a classificação com o modelo treinado.\n",
    "for t, c in zip (testes,modelo.predict(freq_testes)):\n",
    "    print (t +\", \"+ c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URzT5h0pN-Qr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.01, 0.99, 0.  ],\n",
       "       [0.  , 0.98, 0.02],\n",
       "       [0.  , 1.  , 0.  ],\n",
       "       [0.02, 0.01, 0.97],\n",
       "       [0.  , 0.02, 0.97]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Probabilidades de cada classe\n",
    "print (modelo.classes_)\n",
    "modelo.predict_proba(freq_testes).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OjrcFuYNN-Qv"
   },
   "source": [
    "## ** Função de Tags de Negações**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hl7fpNi4N-Qw"
   },
   "source": [
    "* Acrescenta uma tag _NEG encontrada após um 'não'.\n",
    "* Objetivo é dar mais peso para o modelo identificar uma inversão de sentimento da frase.\n",
    "* Exemplos: \n",
    "    - Eu gosto de cachorros, positivo.\n",
    "    - Eu **não** gosto de cachorros, negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0uWFI7CN-Qw"
   },
   "outputs": [],
   "source": [
    "def marque_negacao(texto):\n",
    "    negacoes = ['dont','not']\n",
    "    negacao_detectada = False\n",
    "    resultado = []\n",
    "    palavras = texto.split()\n",
    "    for p in palavras:\n",
    "        p = p.lower()\n",
    "        if negacao_detectada == True:\n",
    "            p = p + '_NEG'\n",
    "        if p in negacoes:\n",
    "            negacao_detectada = True\n",
    "        resultado.append(p)\n",
    "    return (\" \".join(resultado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VnEGlbyQN-Q1"
   },
   "source": [
    "**Exemplos de utilização da tag de negações**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZZNWh2YN-Q1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thats not ya_NEG bitch_NEG if_NEG she_NEG dont_NEG love_NEG giving_NEG you_NEG head_NEG'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marque_negacao('Thats not ya bitch if she dont love giving you head')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3XE8NMBN-Q3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\" these hoes like niggas that spend money not talk_NEG bout_NEG it_NEG \"_NEG'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marque_negacao('\" these hoes like niggas that spend money not talk bout it \"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuMo0NyzN-Q6"
   },
   "source": [
    "## **Criando modelos com Pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QV9ZaTo4N-Q7"
   },
   "source": [
    "* Pipelines são interessantes para reduzir código e automatizar fluxos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E0W5gpr2N-Q7"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEqd6LpEN-Q-"
   },
   "outputs": [],
   "source": [
    "pipeline_simples = Pipeline([\n",
    "  ('counts', CountVectorizer()),\n",
    "  ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xx83-l2jN-RA"
   },
   "source": [
    "* Pipeline que atribui tag de negacoes nas palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMja6f1_N-RA"
   },
   "outputs": [],
   "source": [
    "pipeline_negacoes = Pipeline([\n",
    "  ('counts', CountVectorizer(tokenizer=lambda text: marque_negacao(text))),\n",
    "  ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3s8IYnTqN-RB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_simples.fit(tweets,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eEe_xi5RN-RF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('counts',\n",
       "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None)),\n",
       " ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_simples.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zFtrsfPLN-RG"
   },
   "source": [
    "* Gera o modelo de negações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7qvoT9KN-RG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('counts', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        str...      vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_negacoes.fit(tweets,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vb_16zLWN-RI"
   },
   "source": [
    "* Etapas do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxAXlTCZN-RI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('counts',\n",
       "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "          dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "          strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=<function <lambda> at 0x00000248A1EC9840>,\n",
       "          vocabulary=None)),\n",
       " ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_negacoes.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uOrdLbpN-RL"
   },
   "source": [
    "## Validando os Modelos com Validação Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ZSO1TDjdN-RL"
   },
   "source": [
    "* Fazendo o cross validation do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdzCoSkdN-RM"
   },
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(pipeline_simples, tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "6wrZIEfGN-RO"
   },
   "source": [
    "* Medindo a acurácia média do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsqVrFdtN-RO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8599443166686842"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "5D32i6aKN-RS"
   },
   "source": [
    "* Medidas de validação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zxOQrd4N-RT"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:518: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [0, 1, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-fc1fc3697126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msentimento\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hate_speech'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'offensive_language'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'neither'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresultados\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentimento\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[0;32m   1551\u001b[0m                                                   \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m                                                   \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m                                                   sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1554\u001b[0m     \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1096\u001b[0m         \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \u001b[0msorted_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[1;32m---> 53\u001b[1;33m                              % str(diff))\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: [0, 1, 2]"
     ]
    }
   ],
   "source": [
    "sentimento=['hate_speech','offensive_language','neither']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKfnnvw4N-RU"
   },
   "source": [
    "* Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsrSrom-N-RW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito    0      1     2    All\n",
      "Real                            \n",
      "0         51   1264   115   1430\n",
      "1         49  18894   247  19190\n",
      "2         17   1779  2367   4163\n",
      "All      117  21937  2729  24783\n"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0_8SCJ9N-RX"
   },
   "source": [
    "## **Modelo com a Tag de Negações**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3l3iT9tN-RX"
   },
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(pipeline_negacoes, tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE_1SUj-N-RZ"
   },
   "source": [
    "* Medindo a acurácia média do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQOijDH7N-RZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6276479845055078"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RAuDaRzrN-Rb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:518: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [0, 1, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-fc1fc3697126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msentimento\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hate_speech'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'offensive_language'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'neither'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresultados\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentimento\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[0;32m   1551\u001b[0m                                                   \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m                                                   \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m                                                   sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1554\u001b[0m     \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1096\u001b[0m         \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \u001b[0msorted_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[1;32m---> 53\u001b[1;33m                              % str(diff))\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: [0, 1, 2]"
     ]
    }
   ],
   "source": [
    "sentimento=['hate_speech','offensive_language','neither']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "xdFPuGoEN-Rd"
   },
   "source": [
    "* Matriz de confusão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ka8d4A9N-Rd"
   },
   "outputs": [],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjTqTnFiN-Rg"
   },
   "source": [
    "## ** Avaliando modelo com Bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pnp_Q6SkN-Rh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('like', 'liked', 'likes')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'like', 'liked' , 'likes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3P6z5RcXN-Ri"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQk6Y-cwN-Rk"
   },
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXjpvOjqN-Rl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8753581083807449"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9j4l-8Y3N-Rn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruno\\Anaconda3\\lib\\site-packages\\numpy\\lib\\arraysetops.py:518: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  mask &= (ar1 != a)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: [0, 1, 2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-50-fc1fc3697126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msentimento\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hate_speech'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'offensive_language'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'neither'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresultados\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentimento\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[0;32m   1551\u001b[0m                                                   \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1552\u001b[0m                                                   \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1553\u001b[1;33m                                                   sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m   1554\u001b[0m     \u001b[0mrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1096\u001b[0m         \u001b[0mle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m         \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m         \u001b[0msorted_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    255\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_encode_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36m_encode_numpy\u001b[1;34m(values, uniques, encode)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             raise ValueError(\"y contains previously unseen labels: %s\"\n\u001b[1;32m---> 53\u001b[1;33m                              % str(diff))\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0mencoded\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0muniques\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y contains previously unseen labels: [0, 1, 2]"
     ]
    }
   ],
   "source": [
    "sentimento=['hate_speech','offensive_language','neither']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zTMXL2tN-Ro"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito    0      1     2    All\n",
      "Real                            \n",
      "0        173   1097   160   1430\n",
      "1        289  18272   629  19190\n",
      "2         41    873  3249   4163\n",
      "All      503  20242  4038  24783\n"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classificação_tweets.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
