{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>&nbsp;</p>\n",
    "</p><h1 style=\"text-align: center;\"><strong>DETECÇÃO AUTOMATIZADA DE NOTÍCIAS FALSAS:</strong></h1>\n",
    "<h2 style=\"text-align: center;\"><strong>PESQUISA COM RECONHECIMENTO DE INTEGRIDADE DAS INFORMAÇÕES</strong></h2>\n",
    "<p>&nbsp;</p><p>&nbsp;</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</p><h4 style=\"text-align: center;\"><strong>Proposta de Tema para Trabalho de Conclusão do Curso de Especialização em Ciência de Dados.</strong></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "</p><h3 style=\"text-align: center;\"><strong>Faculdade de Engenharia de Sorocaba - FACENS</strong></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "Proposto por:\n",
    "\n",
    "- Alex Cozer Abrantes (RA:183150) \n",
    "- Bruno Alves Comitre (RA:183141)\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><strong>Sum&aacute;rio</strong></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li><a href='#imports'>1. Imports</a></li>\n",
    "    <li><a href='#recebendo_dados'>2. Recebendo Conjunto de Dados</a></li>\n",
    "    <li><a href='#classificacao_variaveis'>3. Classificação da Variáveis</a></li>\n",
    "    <li><a href='#dicionario_dados'>4. Dicionário dos Dados</a></li>\n",
    "    <li><a href='#conjunto_dados'>5. Perfil do Conjunto de Dados</a></li>\n",
    "    <li><a href='#aprendizado_maquina'>6. Aprendizado de Máquina</a></li>\n",
    "    <li><a href='#criando_modelo'>7. Criando Modelo</a></li>\n",
    "    <li><a href='#resultado'>8. Resultado</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='imports'></a>\n",
    "<h2><strong>1. Imports</strong></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='recebendo_dados'></a>\n",
    "<h2><strong>2. Recebendo Conjunto de Dados</strong></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = 'train_refatorado.csv'\n",
    "path_test = 'test.csv'\n",
    "\n",
    "train_data = pd.read_csv(path_train, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='classificacao_variaveis'></a>\n",
    "<h2><strong>3. Classifica&ccedil;&atilde;o da Vari&aacute;veis</strong></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variável</th>\n",
       "      <th>Classificação</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id</td>\n",
       "      <td>Nominal Qualitativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>title</td>\n",
       "      <td>Nominal Qualitativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>author</td>\n",
       "      <td>Nominal Qualitativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text</td>\n",
       "      <td>Nominal Qualitativo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>label</td>\n",
       "      <td>Quantitativo Discreto</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Variável          Classificação\n",
       "0       id    Nominal Qualitativo\n",
       "1    title    Nominal Qualitativo\n",
       "2   author    Nominal Qualitativo\n",
       "3     text    Nominal Qualitativo\n",
       "4    label  Quantitativo Discreto"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = [[\"id\",\"Nominal Qualitativo\"],[\"title\",\"Nominal Qualitativo\"],\n",
    "         [\"author\",\"Nominal Qualitativo\"],[\"text\",\"Nominal Qualitativo\"],\n",
    "         [\"label\",\"Quantitativo Discreto\"]]\n",
    "\n",
    "filing = pd.DataFrame(table, columns=[\"Variável\", \"Classificação\"])\n",
    "filing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dicionario_dados'></a>\n",
    "<h2><strong>4. Dicion&aacute;rio dos Dados</strong></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "    \n",
    "    \n",
    "- **ID:** ID exclusivo para um artigo de notícias\n",
    "\n",
    "\n",
    "- **TITLE:** título de uma notícia\n",
    "\n",
    "\n",
    "- **AUTHOR:** autor da notícia\n",
    "\n",
    "\n",
    "- **TEXT:** texto do artigo (pode estar incompleto)\n",
    "\n",
    "\n",
    "- **LABEL:** rótulo que marca se a notícia é potencialmente não confiável\n",
    " - 1: não confiável\n",
    " - 0: confiável\n",
    " </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conjunto_dados'></a>\n",
    "<h2><strong>5. Perfil do Conjunto de Dados</strong></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "Visualizando os cinco primeiros registros.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>title_token</th>\n",
       "      <th>title_comprimento</th>\n",
       "      <th>title_num_exclamação</th>\n",
       "      <th>title_num_questao</th>\n",
       "      <th>title_num_puntuacao</th>\n",
       "      <th>...</th>\n",
       "      <th>text_verbos</th>\n",
       "      <th>text_substantivos_vs_comprimento</th>\n",
       "      <th>text_adjetivos_vs_comprimento</th>\n",
       "      <th>text_verbos_vs_comprimento</th>\n",
       "      <th>text_substantivos_vs_palavras</th>\n",
       "      <th>text_adjetivos_vs_palavras</th>\n",
       "      <th>text_verbos_vs_palavras</th>\n",
       "      <th>text_contagem_palavras</th>\n",
       "      <th>text_media_palavras_len</th>\n",
       "      <th>text_por_cento</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20744</td>\n",
       "      <td>The Battleship Debate</td>\n",
       "      <td>Michael Shrimpton</td>\n",
       "      <td>By Michael Shrimpton on October 30, 2016 Some ...</td>\n",
       "      <td>1</td>\n",
       "      <td>['the', 'battleship', 'debate']</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>525</td>\n",
       "      <td>0.055654</td>\n",
       "      <td>0.014497</td>\n",
       "      <td>0.029160</td>\n",
       "      <td>0.329497</td>\n",
       "      <td>0.085827</td>\n",
       "      <td>0.172641</td>\n",
       "      <td>527</td>\n",
       "      <td>4.904965</td>\n",
       "      <td>10.818810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17858</td>\n",
       "      <td>Re: America Is The Loneliest Country In The Wo...</td>\n",
       "      <td>Celine</td>\n",
       "      <td>America Is The Loneliest Country In The Worl...</td>\n",
       "      <td>1</td>\n",
       "      <td>['re', 'america', 'is', 'the', 'loneliest', 'c...</td>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>669</td>\n",
       "      <td>0.048343</td>\n",
       "      <td>0.015837</td>\n",
       "      <td>0.032701</td>\n",
       "      <td>0.272677</td>\n",
       "      <td>0.089330</td>\n",
       "      <td>0.184450</td>\n",
       "      <td>414</td>\n",
       "      <td>4.617590</td>\n",
       "      <td>10.366694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5782</td>\n",
       "      <td>How America's Elections Are Hacked, Missing Li...</td>\n",
       "      <td>The European Union Times</td>\n",
       "      <td>\\n\\nBlack Box Voting, founded in 2003, perform...</td>\n",
       "      <td>1</td>\n",
       "      <td>['how', 'america', 's', 'elections', 'are', 'h...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.062402</td>\n",
       "      <td>0.015601</td>\n",
       "      <td>0.026521</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>15</td>\n",
       "      <td>5.066667</td>\n",
       "      <td>14.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13697</td>\n",
       "      <td>Mark Ruffalo Reportedly Placed on U.S. Terrori...</td>\n",
       "      <td>Alex Ansary</td>\n",
       "      <td>Mark Ruffalo Reportedly Placed on U.S. Terrori...</td>\n",
       "      <td>1</td>\n",
       "      <td>['mark', 'ruffalo', 'reportedly', 'placed', 'o...</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>20</td>\n",
       "      <td>0.068584</td>\n",
       "      <td>0.009956</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>0.418919</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>36</td>\n",
       "      <td>5.074324</td>\n",
       "      <td>10.810811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2121</td>\n",
       "      <td>Hillary Clinton’s Elections 2016 concession sp...</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "      <td>19 mins ago 3 Views 0 Comments 0 Likes It's fa...</td>\n",
       "      <td>1</td>\n",
       "      <td>['hillary', 'clinton', 's', 'elections', '2016...</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.081633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020408</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>3</td>\n",
       "      <td>4.913043</td>\n",
       "      <td>13.043478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  20744                              The Battleship Debate   \n",
       "1  17858  Re: America Is The Loneliest Country In The Wo...   \n",
       "2   5782  How America's Elections Are Hacked, Missing Li...   \n",
       "3  13697  Mark Ruffalo Reportedly Placed on U.S. Terrori...   \n",
       "4   2121  Hillary Clinton’s Elections 2016 concession sp...   \n",
       "\n",
       "                     author  \\\n",
       "0         Michael Shrimpton   \n",
       "1                    Celine   \n",
       "2  The European Union Times   \n",
       "3               Alex Ansary   \n",
       "4   Truth Broadcast Network   \n",
       "\n",
       "                                                text  label  \\\n",
       "0  By Michael Shrimpton on October 30, 2016 Some ...      1   \n",
       "1    America Is The Loneliest Country In The Worl...      1   \n",
       "2  \\n\\nBlack Box Voting, founded in 2003, perform...      1   \n",
       "3  Mark Ruffalo Reportedly Placed on U.S. Terrori...      1   \n",
       "4  19 mins ago 3 Views 0 Comments 0 Likes It's fa...      1   \n",
       "\n",
       "                                         title_token  title_comprimento  \\\n",
       "0                    ['the', 'battleship', 'debate']                 21   \n",
       "1  ['re', 'america', 'is', 'the', 'loneliest', 'c...                115   \n",
       "2  ['how', 'america', 's', 'elections', 'are', 'h...                 59   \n",
       "3  ['mark', 'ruffalo', 'reportedly', 'placed', 'o...                 59   \n",
       "4  ['hillary', 'clinton', 's', 'elections', '2016...                 86   \n",
       "\n",
       "   title_num_exclamação  title_num_questao  title_num_puntuacao  ...  \\\n",
       "0                     0                  0                    0  ...   \n",
       "1                     0                  1                    1  ...   \n",
       "2                     0                  0                    1  ...   \n",
       "3                     0                  0                    2  ...   \n",
       "4                     0                  0                    1  ...   \n",
       "\n",
       "   text_verbos  text_substantivos_vs_comprimento  \\\n",
       "0          525                          0.055654   \n",
       "1          669                          0.048343   \n",
       "2           17                          0.062402   \n",
       "3           20                          0.068584   \n",
       "4            3                          0.081633   \n",
       "\n",
       "   text_adjetivos_vs_comprimento  text_verbos_vs_comprimento  \\\n",
       "0                       0.014497                    0.029160   \n",
       "1                       0.015837                    0.032701   \n",
       "2                       0.015601                    0.026521   \n",
       "3                       0.009956                    0.022124   \n",
       "4                       0.000000                    0.020408   \n",
       "\n",
       "   text_substantivos_vs_palavras  text_adjetivos_vs_palavras  \\\n",
       "0                       0.329497                    0.085827   \n",
       "1                       0.272677                    0.089330   \n",
       "2                       0.380952                    0.095238   \n",
       "3                       0.418919                    0.060811   \n",
       "4                       0.521739                    0.000000   \n",
       "\n",
       "   text_verbos_vs_palavras  text_contagem_palavras  text_media_palavras_len  \\\n",
       "0                 0.172641                     527                 4.904965   \n",
       "1                 0.184450                     414                 4.617590   \n",
       "2                 0.161905                      15                 5.066667   \n",
       "3                 0.135135                      36                 5.074324   \n",
       "4                 0.130435                       3                 4.913043   \n",
       "\n",
       "   text_por_cento  \n",
       "0       10.818810  \n",
       "1       10.366694  \n",
       "2       14.285714  \n",
       "3       10.810811  \n",
       "4       13.043478  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">Vamos criar duas novas colunas, denominadas \"title_author_text\" e \"len_title_author_text\", para armazenar a concatena&ccedil;&atilde;o do t&iacute;tulo, autor, texto e tamanho do recurso.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['title_author_text'] = train_data['title'] + ' ' + train_data['author'] + ' ' + train_data['text']\n",
    "train_data['len_title_author_text'] = [len(x) for x in train_data['title_author_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     15848.000000\n",
      "mean       4816.363579\n",
      "std        5379.737146\n",
      "min          23.000000\n",
      "25%        1824.000000\n",
      "50%        3630.000000\n",
      "75%        6520.500000\n",
      "max      143053.000000\n",
      "Name: len_title_author_text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "detail = train_data['len_title_author_text'].describe()\n",
    "print(detail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='aprendizado_maquina'></a>\n",
    "<h2><strong>6. Aprendizado de M&aacute;quina</strong></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "Vamos separar o conjunto de dados em 80% de Treinamento e 20% de Teste.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de Treino - Feature: 12678\n",
      "Dados de Treino - Label: 12678\n",
      " \n",
      "Dados de Teste - Feature: 3170\n",
      "Dados de Teste - Label: 3170\n"
     ]
    }
   ],
   "source": [
    "#train_features = train_data.drop(['id', 'label'], axis=1)\n",
    "train_features = train_data['title_author_text']\n",
    "train_targets = train_data['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_features, train_targets, test_size=0.2, random_state=42)\n",
    "\n",
    "print('Dados de Treino - Feature: {}'.format(len(X_train)))\n",
    "print('Dados de Treino - Label: {}'.format(len(y_train)))\n",
    "print(' ')\n",
    "print('Dados de Teste - Feature: {}'.format(len(X_test)))\n",
    "print('Dados de Teste - Label: {}'.format(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Corrigir seed aleatório para qualidade de reprodução\n",
    "# Este método é chamado quando o RandomState é inicializado.\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "Criando um dicion&aacute;rio de token com no m&aacute;ximo 5000 palavras.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_token = 5000\n",
    "token = Tokenizer(num_words = num_token, filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "token.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "Precisamos truncar e preencher as sequ&ecirc;ncias de entrada para que elas tenham o mesmo comprimento para modelagem.\n",
    "</p>\n",
    "<p style=\"text-align: justify;\">\n",
    "Vetores do mesmo comprimento s&atilde;o necess&aacute;rios para executar o c&aacute;lculo em Keras.\n",
    "</p>\n",
    "<p style=\"text-align: justify;\">\n",
    "Usamos como tamanho m&aacute;ximo de sequ&ecirc;ncia a m&eacute;dia do recurso \"len_title_author_text\".\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_review_length = int(detail['mean'])\n",
    "\n",
    "x_train_token = token.texts_to_sequences(X_train)\n",
    "x_test_token = token.texts_to_sequences(X_test)\n",
    "\n",
    "X_train_seq = sequence.pad_sequences(x_train_token, maxlen=max_review_length)\n",
    "X_test_seq = sequence.pad_sequences(x_test_token, maxlen=max_review_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='criando_modelo'></a>\n",
    "<h2><strong>7. Criando Modelo</strong></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "A primeira camada é a Camada incorporada que usa 32 vetores de comprimento para representar cada palavra.\n",
    "</p>\n",
    "<p style=\"text-align: justify;\">\n",
    "A próxima camada é a camada LSTM com 100 unidades de memória.\n",
    "</p>\n",
    "<p style=\"text-align: justify;\">\n",
    "Como este é um problema de classificação, usamos uma camada de saída Densa com um único neurônio e uma função de ativação sigmoide para fazer as previsões 0 ou 1 para as duas classes (Não Confiável e Confiável).\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cliente\\Anaconda3\\envs\\University\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "embedding_vector_length = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=num_token, output_dim=embedding_vector_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "#model.add(Dense(units = 256, activation = 'relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observação:**\n",
    "\n",
    "<p style=\"text-align: justify;\">\n",
    "Redes neurais recorrentes, como o LSTM, geralmente têm o problema de sobre ajuste (overfitting), então vamos usar as camadas de eliminação com o Dropout Keras.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cliente\\Anaconda3\\envs\\University\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 4812, 32)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.2\n",
    "\n",
    "model.add(Dropout(dropout))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">\n",
    "Usaremos a função logloss (binary_crossentropy) e o algoritmo de otimização do ADAM.\n",
    "</p>\n",
    "<p style=\"text-align: justify;\">\n",
    "O modelo é adequado para apenas duas épocas com um lote de 64 classificações para espaçar as atualizações de peso.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cliente\\Anaconda3\\envs\\University\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      "12678/12678 [==============================] - 1373s 108ms/step - loss: 1.8584 - acc: 0.7537\n",
      "Epoch 2/3\n",
      "12678/12678 [==============================] - 1370s 108ms/step - loss: 1.7590 - acc: 0.8433\n",
      "Epoch 3/3\n",
      "12678/12678 [==============================] - 1326s 105ms/step - loss: 1.7719 - acc: 0.8504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x295b6378860>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_seq, y_train, epochs=3, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='resultado'></a>\n",
    "<h2><strong>8. Resultado</strong></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.25%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(X_test_seq, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><p style=\"text-align: left;\"><strong>REFER&Ecirc;NCIAS</strong></p></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: justify;\">[1] UTK Machine Learning Club. Fake News - Build a system to identify unreliable news articles. 2017. Dispon&iacute;vel em: &lt;https://www.kaggle.com/c/fake-news/data.&gt;. Acesso em: 28 jul. 2019.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>&nbsp;</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
